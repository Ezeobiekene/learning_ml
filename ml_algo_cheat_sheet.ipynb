{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Algorithms Grouped by Regression vs Classification"
      ],
      "metadata": {
        "id": "_Yvg5WXqmuvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Regression Algorithms**       | **Classification Algorithms**       |\n",
        "| ------------------------------- | ----------------------------------- |\n",
        "| Linear Regression               | Logistic Regression                 |\n",
        "| Ridge Regression                | Decision Tree Classifier            |\n",
        "| Lasso Regression                | Random Forest Classifier            |\n",
        "| ElasticNet                      | Gradient Boosting Classifier        |\n",
        "| Support Vector Regression (SVR) | Support Vector Classification (SVC) |\n",
        "| Decision Tree Regressor         | K-Nearest Neighbors (KNN)           |\n",
        "| Random Forest Regressor         | Naive Bayes                         |\n",
        "| Gradient Boosting Regressor     | Linear Discriminant Analysis (LDA)  |\n",
        "| K-Nearest Neighbors Regressor   | Quadratic Discriminant Analysis     |\n",
        "| Bayesian Regression             | Neural Network Classifier           |\n",
        "| XGBoost Regressor               | XGBoost Classifier                  |\n",
        "| CatBoost Regressor              | CatBoost Classifier                 |\n",
        "| LightGBM Regressor              | LightGBM Classifier                 |\n"
      ],
      "metadata": {
        "id": "i-o8YBvsm8rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression Algorithms"
      ],
      "metadata": {
        "id": "7CnyNcd8nmJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Algorithm**                   | **Example**                              |\n",
        "| ------------------------------- | ---------------------------------------- |\n",
        "| **Linear Regression**           | `LinearRegression().fit(X, y)`           |\n",
        "| **Ridge Regression**            | `Ridge().fit(X, y)`                      |\n",
        "| **Lasso Regression**            | `Lasso().fit(X, y)`                      |\n",
        "| **ElasticNet**                  | `ElasticNet().fit(X, y)`                 |\n",
        "| **SVR**                         | `SVR().fit(X, y)`                        |\n",
        "| **Decision Tree Regressor**     | `DecisionTreeRegressor().fit(X, y)`      |\n",
        "| **Random Forest Regressor**     | `RandomForestRegressor().fit(X, y)`      |\n",
        "| **Gradient Boosting Regressor** | `GradientBoostingRegressor().fit(X, y)`  |\n",
        "| **KNN Regressor**               | `KNeighborsRegressor().fit(X, y)`        |\n",
        "| **Bayesian Ridge**              | `BayesianRidge().fit(X, y)`              |\n",
        "| **XGBoost Regressor**           | `XGBRegressor().fit(X, y)`               |\n",
        "| **CatBoost Regressor**          | `CatBoostRegressor(verbose=0).fit(X, y)` |\n",
        "| **LightGBM Regressor**          | `LGBMRegressor().fit(X, y)`              |\n"
      ],
      "metadata": {
        "id": "wxC-fFsUnq4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Algorithms"
      ],
      "metadata": {
        "id": "g1GsNb4snwk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Algorithm**                    | **Example**                                 |\n",
        "| -------------------------------- | ------------------------------------------- |\n",
        "| **Logistic Regression**          | `LogisticRegression().fit(X, y)`            |\n",
        "| **Decision Tree Classifier**     | `DecisionTreeClassifier().fit(X, y)`        |\n",
        "| **Random Forest Classifier**     | `RandomForestClassifier().fit(X, y)`        |\n",
        "| **Gradient Boosting Classifier** | `GradientBoostingClassifier().fit(X, y)`    |\n",
        "| **SVC**                          | `SVC().fit(X, y)`                           |\n",
        "| **KNN Classifier**               | `KNeighborsClassifier().fit(X, y)`          |\n",
        "| **Naive Bayes**                  | `GaussianNB().fit(X, y)`                    |\n",
        "| **LDA**                          | `LinearDiscriminantAnalysis().fit(X, y)`    |\n",
        "| **QDA**                          | `QuadraticDiscriminantAnalysis().fit(X, y)` |\n",
        "| **MLP Classifier (Neural Net)**  | `MLPClassifier().fit(X, y)`                 |\n",
        "| **XGBoost Classifier**           | `XGBClassifier().fit(X, y)`                 |\n",
        "| **CatBoost Classifier**          | `CatBoostClassifier(verbose=0).fit(X, y)`   |\n",
        "| **LightGBM Classifier**          | `LGBMClassifier().fit(X, y)`                |\n"
      ],
      "metadata": {
        "id": "H4stwOdon1m4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General Flow Of ML model Building"
      ],
      "metadata": {
        "id": "vYp0JTNArwG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Collecting Data\n",
        "\n",
        "2. Cleaning Data\n",
        "  - Perform light EDA\n",
        "  - Remove outliers\n",
        "  - fill or drop na values\n",
        "  - remove duplicates\n",
        "\n",
        "3. Feature Engineering\n",
        "  - Create new features\n",
        "  - Encode categorical variables(OneHotEncoder or LabelEncoder)\n",
        "  - Scale/normalize numeric feature (StandardScaler or MinMaxScaler)\n",
        "  - PCA - reduce multicollinearity\n",
        "\n",
        "4. Exploratory Data Analysis (EDA)\n",
        "  - Visualize target variables\n",
        "  - Explore relationshipa(corr, heatmap, scatter plot, hist)\n",
        "  - Make hist for all numeric columns/features\n",
        "  - Run value_counts on all categorical features/columns and also the target feature\n",
        "\n",
        "5. Model Selection\n",
        "  - Choose 2-3 model types for the problem\n",
        "    - Logistic reg, Random Forest, XGBoost(for classification)\n",
        "    - Linear reg, SVR, Gradient Boosting(for regression)\n",
        "\n",
        "6. Split the Data\n",
        "  - Use train_test_split - usually 80/20 or 70/30\n",
        "  \n",
        "7. Train and Tune Models\n",
        "  - Use cross-validation (cross_val_score, GridSearchCV, or RandomizedSearchCV)\n",
        "  - Tune hyperparameters\n",
        "  - Evaluate with proper metrics:\n",
        "    - Classification: accuracy, precision, recall, F1, ROC AUC\n",
        "    - Regression: RMSE, MAE, RÂ²\n",
        "\n",
        "8. Ensemble If Needed\n",
        "  - Combine best models using Bagging, Boosting, or Stacking\n",
        "  - Use voting classifier or blending if appropriate\n",
        "\n",
        "9. Evaluate Final Model\n",
        "  - Test final model on hold-out test set\n",
        "  - Compare with baseline performance\n",
        "  - Check for overfitting (train vs test performance gap)\n",
        "\n",
        "10. Export and Use\n",
        "  - Save model with joblib or pickle\n",
        "  - Document features and data processing steps\n",
        "  - Optional: build a pipeline (Pipeline from sklearn)"
      ],
      "metadata": {
        "id": "qjxcKtaqsKP4"
      }
    }
  ]
}